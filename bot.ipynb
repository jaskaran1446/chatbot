{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import itertools\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if gpu else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = \"cornell_movie_dialogs_corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_path = os.path.join(FOLDER, 'movie_lines.txt')\n",
    "conv_path = os.path.join(FOLDER, 'movie_conversations.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!'\n",
      "b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!'\n",
      "b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.'\n",
      "b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?'\n",
      "b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\"\n",
      "b'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow'\n",
      "b\"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\"\n",
      "b'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No'\n",
      "b'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?'\n",
      "b'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?'\n"
     ]
    }
   ],
   "source": [
    "with open(line_path, 'rb') as f:\n",
    "    lines = f.readlines()\n",
    "for l in lines[:10]:\n",
    "    print(l.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['lineid', 'charid', 'movieid', 'charname', 'text']\n",
    "lines = {}\n",
    "with open(line_path, 'r', encoding='iso-8859-1') as f:\n",
    "    for line in f.readlines():\n",
    "        split = line.split(' +++$+++ ')\n",
    "        lineobj = {}\n",
    "        for i, fname in enumerate(fields):\n",
    "            lineobj[fname] = split[i]\n",
    "        lines[lineobj['lineid']] = lineobj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lineid': 'L105',\n",
       " 'charid': 'u8',\n",
       " 'movieid': 'm0',\n",
       " 'charname': 'MISS PERKY',\n",
       " 'text': \"Well, yes, compared to your other choices of expression this year, today's events are quite mild.  By the way, Bobby Rictor's gonad retrieval operation went quite well, in case you're interested.\\n\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines['L105']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']\"\n",
      "b\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']\"\n"
     ]
    }
   ],
   "source": [
    "with open(conv_path, 'rb') as f:\n",
    "    c_lines = f.readlines()\n",
    "for l in c_lines[:10]:\n",
    "    print(l.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['char1id', 'char2id', 'movieid', 'lineids']\n",
    "conversations = []\n",
    "with open(conv_path, 'r', encoding='iso-8859-1') as f:\n",
    "    for line in f.readlines():\n",
    "        split = line.split(' +++$+++ ')\n",
    "        convobj = {}\n",
    "        for i, fname in enumerate(fields):\n",
    "            convobj[fname] = split[i]\n",
    "        convobj['lineids'] = eval(convobj['lineids'])\n",
    "        #creating a key for the dict\n",
    "        all_lines = []\n",
    "        for lid in convobj['lineids']:\n",
    "            all_lines.append(lines[lid])\n",
    "        convobj['lines'] = all_lines\n",
    "        conversations.append(convobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'char1id': 'u0',\n",
       " 'char2id': 'u2',\n",
       " 'movieid': 'm0',\n",
       " 'lineids': ['L194', 'L195', 'L196', 'L197'],\n",
       " 'lines': [{'lineid': 'L194',\n",
       "   'charid': 'u0',\n",
       "   'movieid': 'm0',\n",
       "   'charname': 'BIANCA',\n",
       "   'text': 'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\n'},\n",
       "  {'lineid': 'L195',\n",
       "   'charid': 'u2',\n",
       "   'movieid': 'm0',\n",
       "   'charname': 'CAMERON',\n",
       "   'text': \"Well, I thought we'd start with pronunciation, if that's okay with you.\\n\"},\n",
       "  {'lineid': 'L196',\n",
       "   'charid': 'u0',\n",
       "   'movieid': 'm0',\n",
       "   'charname': 'BIANCA',\n",
       "   'text': 'Not the hacking and gagging and spitting part.  Please.\\n'},\n",
       "  {'lineid': 'L197',\n",
       "   'charid': 'u2',\n",
       "   'movieid': 'm0',\n",
       "   'charname': 'CAMERON',\n",
       "   'text': \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\"}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = []\n",
    "for conversation in conversations:\n",
    "    for i in range(len(conversation['lines']) - 1):\n",
    "        q = conversation['lines'][i]['text'].strip()\n",
    "        a = conversation['lines'][1+i]['text'].strip()\n",
    "        if q and a:\n",
    "            qa_pairs.append((q,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.',\n",
       " \"Well, I thought we'd start with pronunciation, if that's okay with you.\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#save to csv\n",
    "csv_name = 'formatted_lines.txt'\n",
    "csv_path = os.path.join(FOLDER, csv_name)\n",
    "delim = '\\t'\n",
    "delim = str(codecs.decode(delim, 'unicode_escape'))\n",
    "\n",
    "with open(csv_path, 'w', encoding='utf-8') as fn:\n",
    "    writer = csv.writer(fn, delimiter=delim)\n",
    "    for qa in qa_pairs:\n",
    "        writer.writerow(qa)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\n\", \"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\n\", \"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\", \"You're asking me out.  That's so cute. What's your name again?\\tForget it.\\n\", \"No, no, it's my fault -- we didn't have a proper introduction ---\\tCameron.\\n\"]\n"
     ]
    }
   ],
   "source": [
    "with open(csv_path, 'r') as f:\n",
    "    c_lines = f.readlines()[:5]\n",
    "print(c_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "SOS = 1\n",
    "EOS = 2\n",
    "\n",
    "class Vocabulary(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2id = {}\n",
    "        self.word2count = {}\n",
    "        self.id2word = {PAD:'PAD', SOS:'SOS', EOS:'EOS'}\n",
    "        self.word_count = 3\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word in self.word2id:\n",
    "            self.word2count[word] += 1\n",
    "        else:\n",
    "            self.word2id[word] = self.word_count\n",
    "            self.word2count[word] = 1\n",
    "            self.id2word[self.word_count] = word\n",
    "            self.word_count += 1\n",
    "    \n",
    "    def add_sentence(self, sent):\n",
    "        for word in sent.split():\n",
    "            self.add_word(word)\n",
    "            \n",
    "    def trim(self, min_count):\n",
    "        keep_list = []\n",
    "        for k,v in zip(self.word2count.keys(), self.word2count.values()):\n",
    "            if v >= min_count:\n",
    "                keep_list.append(k)\n",
    "        self.word2id = {}\n",
    "        self.word2count = {}\n",
    "        self.id2word = {PAD:'PAD', SOS:'SOS', EOS:'EOS'}\n",
    "        self.word_count = 3\n",
    "        for word in keep_list:\n",
    "            self.add_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode2ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "    #normal form decomposed, non-marking space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Montreal'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicode2ascii('Montr√©al')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    s = unicode2ascii(s.lower().strip())\n",
    "    \n",
    "    #replace .?! by ' .'\n",
    "    s = re.sub(r'([.!?])', r' \\1', s)\n",
    "    #replace non alphabet, punctuation with whitespace\n",
    "    s = re.sub(r'[^a-zA-Z.!?]+', r' ', s)\n",
    "    #remove continuous whites\n",
    "    s = re.sub(r'\\s+', r' ', s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa ! n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_string('aa!   n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(csv_path, 'r', encoding = 'utf-8').read().strip().split('\\n')\n",
    "pairs = []\n",
    "for line in lines:\n",
    "    pairs.append([normalize_string(s) for s in line.split('\\t')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['can we make this quick ? roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad . again .',\n",
       " 'well i thought we d start with pronunciation if that s okay with you .']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(pairs))\n",
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary('cornell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "def filter_words(qa):\n",
    "    return len(qa[0].split()) < MAX_LENGTH and len(qa[1].split()) < MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pairs(pairs):\n",
    "    return [p for p in pairs if filter_words(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pairs of length >= 2: 221282\n",
      "pairs after filtering 64271\n"
     ]
    }
   ],
   "source": [
    "pairs = [p for p in pairs if len(p)>1]\n",
    "print('pairs of length >= 2:', len(pairs))\n",
    "pairs = filter_pairs(pairs)\n",
    "print('pairs after filtering', len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs[0][0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18007"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for pair in pairs:\n",
    "    vocab.add_sentence(pair[0])\n",
    "    vocab.add_sentence(pair[1])\n",
    "vocab.word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trim rare words and the pairs in which they appear\n",
    "MIN_COUNT = 4\n",
    "def trim_rare_words(voc, pairs, min_c = MIN_COUNT):\n",
    "    voc.trim(min_c)\n",
    "    temp_pairs = []\n",
    "    for p in pairs:\n",
    "        keep = True\n",
    "        for wq in p[0].split():\n",
    "            if wq not in voc.word2id :\n",
    "                keep = False\n",
    "                break\n",
    "        if keep:\n",
    "            for wa in p[1].split():\n",
    "                if wa not in voc.word2id :\n",
    "                    keep = False\n",
    "                    break\n",
    "            if keep:\n",
    "                temp_pairs.append(p)\n",
    "    return temp_pairs   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49781"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = trim_rare_words(vocab, pairs)\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_index(voc, s):\n",
    "    return [voc.word2id[w] for w in s.split()] + [EOS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3, 4, 2]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pairs[0][0])\n",
    "sentence_to_index(vocab, pairs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero pad for variable length\n",
    "def zero_pad(v, val=0):\n",
    "    return list(itertools.zip_longest(*v, fillvalue=val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 8, 9, 10, 4, 11, 12, 13, 2] [3, 4, 2]\n",
      "[(7, 3), (8, 4), (9, 2), (10, 0), (4, 0), (11, 0), (12, 0), (13, 0), (2, 0)]\n"
     ]
    }
   ],
   "source": [
    "i = sentence_to_index(vocab,pairs[1][0])\n",
    "j = sentence_to_index(vocab,pairs[0][0])\n",
    "print(i,j)\n",
    "print(zero_pad((i,j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarizer(l, val=0):\n",
    "    m = []\n",
    "    for i, row in enumerate(l):\n",
    "        m.append([])\n",
    "        for v in row:\n",
    "            if v is not PAD:\n",
    "                m[i].append(1)\n",
    "            else:\n",
    "                m[i].append(val)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(qs, voc):\n",
    "    indices = [sentence_to_index(voc, q) for q in qs]\n",
    "    lens = torch.tensor([len(index) for index in indices])\n",
    "    zp = torch.LongTensor(zero_pad(indices))\n",
    "    return zp, lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_output(ans, voc):\n",
    "    indices = [sentence_to_index(voc, a) for a in ans]\n",
    "    max_target_len = max([len(index) for index in indices])\n",
    "    zp = zero_pad(indices)\n",
    "    mask = torch.ByteTensor(binarizer(zp))\n",
    "    zp = torch.LongTensor(zp)\n",
    "    return zp, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train_data(voc, pair_batch):\n",
    "    #sort pairs in desc order by ques length\n",
    "    pair_batch.sort(key = lambda x:len(x[0].split(' ')), reverse = True)\n",
    "    ip, op = [], []\n",
    "    for pair in pair_batch:\n",
    "        ip.append(pair[0])\n",
    "        op.append(pair[1])\n",
    "    inputs, lens = prepare_input(ip, voc)\n",
    "    outputs, mask, max_len = prepare_output(op, voc)\n",
    "    return inputs, lens, outputs, mask, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  91,    7,   64,   33, 3973,  155,   38],\n",
      "        [   7,  195,   58,   27,  748,  557,  261],\n",
      "        [ 190,  116,    7,   14, 3052,  558,    4],\n",
      "        [   7,   73,   21,  188,    4,    4,    2],\n",
      "        [   4,    7,    6,    2,    2,    2,    0],\n",
      "        [   4,  131,    2,    0,    0,    0,    0],\n",
      "        [   4,   59,    0,    0,    0,    0,    0],\n",
      "        [   6,    2,    0,    0,    0,    0,    0],\n",
      "        [   2,    0,    0,    0,    0,    0,    0]])\n",
      "tensor([9, 8, 6, 5, 5, 5, 4])\n",
      "tensor([[ 312,   25,  165,   99,   49,   49,  375],\n",
      "        [   4,  195,    4,  265,    6,   46,    7],\n",
      "        [   2,  116,    2,  116,    2,    7,    4],\n",
      "        [   0,   24,    0,  100,    0,  157,  664],\n",
      "        [   0,    4,    0,  621,    0,   97, 1480],\n",
      "        [   0,    2,    0,  110,    0,   36,    4],\n",
      "        [   0,    0,    0,    6,    0,    6,    2],\n",
      "        [   0,    0,    0,    2,    0,    2,    0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1],\n",
      "        [0, 1, 0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 0, 1, 1],\n",
      "        [0, 0, 0, 1, 0, 1, 1],\n",
      "        [0, 0, 0, 1, 0, 1, 0]], dtype=torch.uint8)\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#testing the function above\n",
    "small_sample_size = 7\n",
    "small_pairs = [random.choice(pairs) for _ in range(small_sample_size)]\n",
    "batches = batch_train_data(vocab, small_pairs)\n",
    "for item in batches:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden = hidden\n",
    "        self.embedding = embedding\n",
    "        self.n_layers = n_layers\n",
    "        self.gru = nn.GRU(hidden, hidden, n_layers, dropout = (0 if n_layers==1 else dropout), bidirectional = True)\n",
    "    def forward(self, input_seq, input_lens, hidden=None):\n",
    "        #input_seq = (max_len, batch_size)\n",
    "        #input_lens = (batch_size, )\n",
    "        #hidden = (n_layers*n_directions, batch_size, hidden)\n",
    "        \n",
    "        #calculate embeddings\n",
    "        embs = self.embedding(input_seq)\n",
    "        \n",
    "        #packed padded\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embs, input_lens)\n",
    "        \n",
    "        output, hidden = self.gru(packed, hidden)\n",
    "        \n",
    "        output, _ = torch.nn.utils.rnn.pad_packed_sequence(output)\n",
    "        output = output[:,:,:self.hidden] + output[:,:,self.hidden:]\n",
    "        return output, hidden\n",
    "        #output = (max_len, batch, hidden)\n",
    "        #hidden = (n_layers*n_directions, batch, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, hidden, method='dot'):\n",
    "        super(Attn, self).__init__()\n",
    "        self.hidden = hidden\n",
    "        self.method = method\n",
    "    \n",
    "    def score(self, dec_hidden, enc_op):\n",
    "        #dec_hidden = (1, batch, hidden)\n",
    "        #enc_op = (max_len, batch, hidden)\n",
    "        #prod = (max_len, batch, hidden)=> sum over dim=2 => (max_len, batch)\n",
    "        if self.method == 'dot':\n",
    "            return torch.sum(dec_hidden * enc_op, dim=2)\n",
    "    \n",
    "    def forward(self, dec_h, enc_ops):\n",
    "        \n",
    "        attn_wts = self.score(dec_h, enc_ops)\n",
    "        attn_wts = attn_wts.t() #(batch, max_len)\n",
    "        #take softmax over max_len(timesteps) and unsqueeze\n",
    "        return F.softmax(attn_wts, dim = 1).unsqueeze(1) #(batch, 1, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderWithAttn(nn.Module):\n",
    "    def __init__(self, embedding, hidden, output_size, n_layers=1, dropout=0):\n",
    "        super(DecoderWithAttn, self).__init__()\n",
    "        self.hidden = hidden\n",
    "        self.embedding = embedding\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.attn = Attn(hidden)\n",
    "        self.deconcat = nn.Linear(2*hidden, hidden)\n",
    "        self.out = nn.Linear(hidden, output_size)\n",
    "        self.gru = nn.GRU(hidden, hidden, n_layers, dropout=dropout)\n",
    "        \n",
    "    def forward(self, input_step, last_hidden, encoder_states):\n",
    "        #input_step = (1, batch)\n",
    "        #last_hidden = (n_layers*n_directions, batch, hidden)\n",
    "        #encoder_states = (max_len, batch, n_directions*hidden)\n",
    "        #run one batch word at a time\n",
    "        \n",
    "        embs = self.embedding(input_step)\n",
    "        dec_op, hidden = self.gru(embs, last_hidden)\n",
    "        #(1,batch, n_directions*hidden)\n",
    "        #(n_layers*n_directions, batch, hidden)\n",
    "        #find attn\n",
    "        attn_wt = self.attn(hidden, encoder_states)\n",
    "        #batch, 1, max_len\n",
    "        #multiply attn with enc op\n",
    "        context = attn_wt.bmm(encoder_states.transpose(0,1))\n",
    "        #batch,1,max_len * batch,max_len, dir*hidd = batch, 1, dir*hidd\n",
    "        dec_op = dec_op.squeeze(0) #batch, dir*hidd\n",
    "        context = context.squeeze(1) #batch, dir*hidd\n",
    "        concat_ip = torch.cat((dec_op, context), 1)\n",
    "        concat_op = torch.tanh(self.deconcat(concat_ip))\n",
    "        \n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        output = softmax(self.out(concat_op))\n",
    "        return output, hidden\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskedNLL(output, true, mask):\n",
    "    n_elems = mask.sum()\n",
    "    true = true.view(-1,1)\n",
    "    gathered = torch.gather(output, 1, true)\n",
    "    ce = -torch.log(gathered)\n",
    "    loss= ce.masked_select(mask)\n",
    "    loss = loss.mean().to(device)\n",
    "    return loss, n_elems.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[2789,   85,   36,    5,  123],\n",
      "        [ 101,  296,   37,  209,    9],\n",
      "        [   9,    7,   75,  210,  124],\n",
      "        [ 267,  214,    4, 4437,    4],\n",
      "        [ 584,   82,    4,    6,    2],\n",
      "        [ 186,    4,    4,    2,    0],\n",
      "        [ 316,    2,    2,    0,    0],\n",
      "        [  65,    0,    0,    0,    0],\n",
      "        [   2,    0,    0,    0,    0]])\n",
      "lens: tensor([9, 7, 7, 6, 5])\n",
      "outputs: tensor([[  36,   25,   17, 1423, 1474],\n",
      "        [  37,  214, 1137,    4,    7],\n",
      "        [ 343,   75,   40,    4, 2931],\n",
      "        [  65,    4, 2999,    4,   65],\n",
      "        [   2,    2,    4,    2,    2],\n",
      "        [   0,    0,    2,    0,    0]])\n",
      "mask: tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [0, 0, 1, 0, 0]], dtype=torch.uint8)\n",
      "max_len: 6\n",
      "encoder output: torch.Size([9, 5, 500])\n",
      "encoder hidden: torch.Size([2, 5, 500])\n",
      "decoder input: torch.Size([1, 5])\n",
      "decoder hidden: torch.Size([1, 5, 500])\n",
      "decoder output: torch.Size([5, 6192])\n",
      "decoder hidden: torch.Size([1, 5, 500])\n",
      "decoder input shape initial: torch.Size([5])\n",
      "decoder input shape final: torch.Size([1, 5])\n",
      "mask shape: torch.Size([5])\n",
      "mask: tensor([1, 1, 1, 1, 1], dtype=torch.uint8)\n",
      "mask loss tensor(8.7731, grad_fn=<MeanBackward1>)\n",
      "nt 5\n",
      "total 5.0\n",
      "print loss [43.865604400634766]\n",
      "return 8.773120880126953\n",
      "decoder output: torch.Size([5, 6192])\n",
      "decoder hidden: torch.Size([1, 5, 500])\n",
      "decoder input shape initial: torch.Size([5])\n",
      "decoder input shape final: torch.Size([1, 5])\n",
      "mask shape: torch.Size([5])\n",
      "mask: tensor([1, 1, 1, 1, 1], dtype=torch.uint8)\n",
      "mask loss tensor(8.6617, grad_fn=<MeanBackward1>)\n",
      "nt 5\n",
      "total 10.0\n",
      "print loss [43.865604400634766, 43.308258056640625]\n",
      "return 8.717386245727539\n",
      "decoder output: torch.Size([5, 6192])\n",
      "decoder hidden: torch.Size([1, 5, 500])\n",
      "decoder input shape initial: torch.Size([5])\n",
      "decoder input shape final: torch.Size([1, 5])\n",
      "mask shape: torch.Size([5])\n",
      "mask: tensor([1, 1, 1, 1, 1], dtype=torch.uint8)\n",
      "mask loss tensor(8.6763, grad_fn=<MeanBackward1>)\n",
      "nt 5\n",
      "total 15.0\n",
      "print loss [43.865604400634766, 43.308258056640625, 43.381385803222656]\n",
      "return 8.703683217366537\n",
      "decoder output: torch.Size([5, 6192])\n",
      "decoder hidden: torch.Size([1, 5, 500])\n",
      "decoder input shape initial: torch.Size([5])\n",
      "decoder input shape final: torch.Size([1, 5])\n",
      "mask shape: torch.Size([5])\n",
      "mask: tensor([1, 1, 1, 1, 1], dtype=torch.uint8)\n",
      "mask loss tensor(8.7025, grad_fn=<MeanBackward1>)\n",
      "nt 5\n",
      "total 20.0\n",
      "print loss [43.865604400634766, 43.308258056640625, 43.381385803222656, 43.512635231018066]\n",
      "return 8.703394174575806\n",
      "decoder output: torch.Size([5, 6192])\n",
      "decoder hidden: torch.Size([1, 5, 500])\n",
      "decoder input shape initial: torch.Size([5])\n",
      "decoder input shape final: torch.Size([1, 5])\n",
      "mask shape: torch.Size([5])\n",
      "mask: tensor([1, 1, 1, 1, 1], dtype=torch.uint8)\n",
      "mask loss tensor(8.7551, grad_fn=<MeanBackward1>)\n",
      "nt 5\n",
      "total 25.0\n",
      "print loss [43.865604400634766, 43.308258056640625, 43.381385803222656, 43.512635231018066, 43.775577545166016]\n",
      "return 8.713738441467285\n",
      "decoder output: torch.Size([5, 6192])\n",
      "decoder hidden: torch.Size([1, 5, 500])\n",
      "decoder input shape initial: torch.Size([5])\n",
      "decoder input shape final: torch.Size([1, 5])\n",
      "mask shape: torch.Size([5])\n",
      "mask: tensor([0, 0, 1, 0, 0], dtype=torch.uint8)\n",
      "mask loss tensor(8.7771, grad_fn=<MeanBackward1>)\n",
      "nt 1\n",
      "total 26.0\n",
      "print loss [43.865604400634766, 43.308258056640625, 43.381385803222656, 43.512635231018066, 43.775577545166016, 8.777078628540039]\n",
      "return 8.716174602508545\n"
     ]
    }
   ],
   "source": [
    "#train for small batch\n",
    "small_batch_size = 5\n",
    "small_pairs = [random.choice(pairs) for _ in range(small_batch_size)]\n",
    "batches = batch_train_data(vocab, small_pairs)\n",
    "inputs, lens, outputs, mask, max_len = batches\n",
    "print('inputs:', inputs)\n",
    "print('lens:', lens)\n",
    "print('outputs:', outputs)\n",
    "print('mask:', mask)\n",
    "print('max_len:', max_len)\n",
    "\n",
    "\n",
    "hidden_size=500\n",
    "\n",
    "embeds = nn.Embedding(vocab.word_count, hidden_size)\n",
    "encoder = EncoderRNN(hidden_size, embeds).to(device)\n",
    "decoder = DecoderWithAttn(embeds, hidden_size, vocab.word_count).to(device)\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "encoder_optim = optim.Adam(encoder.parameters(), 0.001)\n",
    "decoder_optim = optim.Adam(decoder.parameters(), 0.001)\n",
    "encoder_optim.zero_grad()\n",
    "decoder_optim.zero_grad()\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "lens = lens.to(device)\n",
    "outputs = outputs.to(device)\n",
    "mask = mask.to(device)\n",
    "\n",
    "loss = 0.\n",
    "print_loss = []\n",
    "total = 0.\n",
    "\n",
    "encoder_out, encoder_hid = encoder(inputs, lens)\n",
    "print('encoder output:', encoder_out.size())\n",
    "print('encoder hidden:', encoder_hid.size())\n",
    "\n",
    "#first decoder input is start symbol\n",
    "decoder_in = torch.LongTensor([[SOS for _ in range(small_batch_size)]]).to(device)\n",
    "print('decoder input:', decoder_in.size())\n",
    "\n",
    "#first hidden of decoder = last hidden of encoder\n",
    "decoder_hid = encoder_hid[:1].to(device)\n",
    "print('decoder hidden:', decoder_hid.size())\n",
    "\n",
    "#using teacher forcing\n",
    "for t in range(max_len):\n",
    "    decoder_out, decoder_hid = decoder(decoder_in, decoder_hid, encoder_out)\n",
    "    print('decoder output:', decoder_out.size())\n",
    "    print('decoder hidden:', decoder_hid.size())\n",
    "    \n",
    "    \n",
    "    print('decoder input shape initial:', outputs[t].size())\n",
    "    #teacher forcing\n",
    "    decoder_in = outputs[t].view(1, -1)\n",
    "    print('decoder input shape final:', decoder_in.size())\n",
    "    print('mask shape:', mask[t].size())\n",
    "    print('mask:', mask[t])\n",
    "    \n",
    "    mask_loss, nt = maskedNLL(decoder_out, outputs[t], mask[t])\n",
    "    print('mask loss', mask_loss)\n",
    "    print('nt',nt)\n",
    "    total+=nt\n",
    "    print('total', total)\n",
    "    print_loss.append(mask_loss.item()*nt)\n",
    "    print('print loss', print_loss)\n",
    "    ls = sum(print_loss)\n",
    "    return_loss = ls/total\n",
    "    print('return', return_loss)\n",
    "    encoder_optim.step()\n",
    "    decoder_optim.step()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actual train function\n",
    "def train(inputs, lens, outputs, mask, max_target_len, batch, embs, encoder, decoder, encoder_optim, decoder_optim, teacher_forcing_ratio):\n",
    "    encoder_optim.zero_grad()\n",
    "    decoder_optim.zero_grad()\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "    lens = lens.to(device)\n",
    "    outputs = outputs.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    loss = 0.\n",
    "    print_loss = []\n",
    "    total = 0.\n",
    "\n",
    "    encoder_out, encoder_hid = encoder(inputs, lens)\n",
    "\n",
    "    #first decoder input is start symbol\n",
    "    decoder_in = torch.LongTensor([[SOS for _ in range(batch)]]).to(device)\n",
    "\n",
    "    #first hidden of decoder = last hidden of encoder\n",
    "    decoder_hid = encoder_hid[:1].to(device)\n",
    "\n",
    "    use_tf = True if random.random()<teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_tf:\n",
    "        for t in range(max_len):\n",
    "            decoder_out, decoder_hid = decoder(decoder_in, decoder_hid, encoder_out)\n",
    "           \n",
    "            #teacher forcing\n",
    "            decoder_in = outputs[t].view(1, -1)\n",
    "\n",
    "            mask_loss, nt = maskedNLL(decoder_out, outputs[t], mask[t])\n",
    "            total += nt\n",
    "            print_loss.append(mask_loss.item()*nt)\n",
    "            loss += mask_loss\n",
    "    else:\n",
    "        for t in range(max_len):\n",
    "            decoder_out, decoder_hid = decoder(decoder_in, decoder_hid, encoder_out)\n",
    "           \n",
    "            _, topk = decoder_out.topk(1)\n",
    "            decoder_in = torch.LongTensor([[topk[i][0] for i in range(batch)]]).to(device)\n",
    "            \n",
    "            mask_loss, nt = maskedNLL(decoder_out, outputs[t], mask[t])\n",
    "            total += nt\n",
    "            print_loss.append(mask_loss.item()*nt)\n",
    "            loss += mask_loss\n",
    "    \n",
    "    loss.backward()\n",
    "    encoder_optim.step()\n",
    "    decoder_optim.step()\n",
    "    \n",
    "    return sum(print_loss)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iters(voc, pairs, encoder, decoder, encoder_optim, decoder_optim, embs, batch, n_iters):\n",
    "    training_batches = [batch_train_data(voc, [random.choice(pairs) for _ in range(batch)])\n",
    "                      for _ in range(n_iters)]\n",
    "    print_loss = 0.\n",
    "    for i in range(n_iters):\n",
    "        current_batch = training_batches[i]\n",
    "        inputs, lens, outputs, mask, max_len = current_batch\n",
    "        loss = train(inputs, lens, outputs, mask, max_len, batch, embs, encoder, decoder, encoder_optim, decoder_optim, 1.0)\n",
    "        print_loss += loss\n",
    "        \n",
    "        if i%200 == 0 and i!=0:\n",
    "            print('Iteration', i)\n",
    "            print(print_loss/200)\n",
    "            print_loss = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to talk to the bot we need a decoder\n",
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, inputs, lens, max_len):\n",
    "        encoder_out, encoder_hid = self.encoder(inputs, lens)\n",
    "        #enc final hidden is in first of decoder\n",
    "        decoder_hid = encoder_hid[:1]\n",
    "        # start symbol\n",
    "        decoder_in = torch.ones(1, 1, device=device, dtype=torch.long) * SOS\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        for _ in range(max_len):\n",
    "            # Forward pass through decoder\n",
    "            decoder_out, decoder_hid = self.decoder(decoder_in, decoder_hid, encoder_out)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_in = torch.max(decoder_out, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_in), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_in = torch.unsqueeze(decoder_in, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=10):\n",
    "    # Format input sentence as a batch\n",
    "    indexes_batch = [sentence_to_index(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch \n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    #index back to word\n",
    "    decoded_words = [voc.id2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            input_sentence = input('> ')\n",
    "            # exit condition\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalize_string(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: <UNK>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 200\n",
      "4.251150501117423\n",
      "Iteration 400\n",
      "3.6769184004841566\n",
      "Iteration 600\n",
      "3.47263782340546\n",
      "Iteration 800\n",
      "3.264304235343397\n",
      "Iteration 1000\n",
      "3.1538263822650983\n",
      "Iteration 1200\n",
      "3.0448477410860137\n",
      "Iteration 1400\n",
      "2.9013089056025727\n",
      "Iteration 1600\n",
      "2.8010474879619944\n",
      "Iteration 1800\n",
      "2.666254231161008\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 500\n",
    "batch_size = 64\n",
    "n_iters = 2000\n",
    "embedding = nn.Embedding(vocab.word_count, hidden_dim)\n",
    "encoder = EncoderRNN(hidden_dim, embedding).to(device)\n",
    "decoder = DecoderWithAttn(embedding, hidden_dim, vocab.word_count).to(device)\n",
    "\n",
    "l_rate = 0.001\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "encoder_optim = optim.Adam(encoder.parameters(), l_rate)\n",
    "decoder_optim = optim.Adam(decoder.parameters(), l_rate)\n",
    "encoder_optim.zero_grad()\n",
    "decoder_optim.zero_grad()\n",
    "\n",
    "train_iters(vocab, pairs, encoder, decoder, encoder_optim, decoder_optim, embedding, batch_size, n_iters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> hi\n",
      "Bot: hi .\n",
      "> how are you?\n",
      "Bot: fine .\n",
      "> quit\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "evaluateInput(encoder, decoder, searcher, vocab)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
